{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":61425,"status":"ok","timestamp":1692441403087,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"ymFxTOcEVo6G","outputId":"28e95957-c356-42e6-8b6f-e5744f627741"},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'roboflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6188\\3403432481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install roboflow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nZWPsNxW55cenzCDFaks\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"roboflow-100\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vehicles-q0x2v\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'"]}],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"nZWPsNxW55cenzCDFaks\")\n","project = rf.workspace(\"roboflow-100\").project(\"vehicles-q0x2v\")\n","dataset = project.version(2).download(\"yolov8\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6471,"status":"ok","timestamp":1692612283997,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"jC3MPmC0Wo_w","outputId":"d9d7d412-d9d1-43e7-944e-e8552daf2e75"},"outputs":[],"source":["pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7288,"status":"ok","timestamp":1692612291273,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"oyrjp3NSV0aI"},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692612291273,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"rfM3lYoLWnZL"},"outputs":[],"source":["from ultralytics import YOLO\n","model = YOLO(r'C:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\runs_1\\detect\\train2\\weights\\best.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5171757,"status":"ok","timestamp":1692112821667,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"kevrtzhAWuep","outputId":"c395a537-fdcb-43d7-c165-f8dab1e3205d"},"outputs":[],"source":["results = model.train(data=r'/content/data.yaml', epochs=100, imgsz=640)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jk8Ko28KX_Ww"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1414,"status":"ok","timestamp":1692114000117,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"CzbQqqFUWzps","outputId":"932f5496-5495-4c54-ab1f-7029c715fe11"},"outputs":[],"source":["import os\n","import shutil\n","from zipfile import ZipFile\n","from IPython.display import FileLink\n","# Replace these with your actual paths\n","folder_path = r\"/content/runs\"\n","rar_filename = \"runs_1.rar\"\n","\n","# Compress the folder into a RAR archive\n","shutil.make_archive(rar_filename, 'zip', folder_path)\n","\n","# Rename the ZIP archive to RAR (if needed)\n","os.rename(f\"{rar_filename}.zip\", f\"{rar_filename}\")\n","\n","# Provide the download link\n","display(FileLink(rar_filename, result_html_prefix=\"Click to download: \"))\n"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":342,"status":"ok","timestamp":1692611328386,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"tM26I2RVl_Vv"},"outputs":[],"source":["def klasifikasi_kemacetan(weight) :\n","  if weight<12 :\n","    return \"sepi\"\n","  elif weight>=12 and weight <30 :\n","    return \"macet\"\n","  else :\n","    return \"sangat macet\""]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692611329767,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"oxlE6XPHm6Qd"},"outputs":[],"source":["\n","    vehicle_weights = {\n","        'big bus': 2,\n","        'big truck': 2,\n","        'bus-l-': 2,\n","        'bus-s-': 1.2,\n","        'car': 1,\n","        'mid truck': 1.5,\n","        'small bus': 1.2,\n","        'small truck': 1.2,\n","        'truck-l-': 2,\n","        'truck-m-': 1.5,\n","        'truck-s-': 1.2,\n","        'truck-xl-': 2\n","    }\n"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692611331138,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"sBuIgQ9Em1RC"},"outputs":[],"source":["def Automatic_toll_pricing(tingkat_kemacetan, harga_normal):\n","    automatic_toll_pricing = {\n","        'big bus': harga_normal*0.8,\n","        'big truck': harga_normal,\n","        'bus-l-':  harga_normal*0.8,\n","        'bus-s-':  harga_normal*0.8,\n","        'car': harga_normal,\n","        'mid truck':  harga_normal,\n","        'small bus': harga_normal*0.8,\n","        'small truck':harga_normal,\n","        'truck-l-': harga_normal,\n","        'truck-m-':  harga_normal,\n","        'truck-s-': harga_normal,\n","        'truck-xl-': harga_normal\n","    }\n","\n","    if tingkat_kemacetan == 'sepi':\n","        return {vehicle_type: harga_normal for vehicle_type in automatic_toll_pricing}\n","    elif tingkat_kemacetan == 'macet':\n","        adjusted_pricing = {vehicle_type: harga * 1.3 if vehicle_type != 'big bus' and vehicle_type != 'small bus'\n","        and vehicle_type != 'bus-l-'and vehicle_type != 'bus-s-' else harga for vehicle_type, harga in automatic_toll_pricing.items()}\n","        return adjusted_pricing\n","    else:\n","        adjusted_pricing = {vehicle_type: harga * 1.5 if vehicle_type != 'big bus' and vehicle_type != 'small bus'\n","        and vehicle_type != 'bus-l-'and vehicle_type != 'bus-s-' else harga for vehicle_type, harga in automatic_toll_pricing.items()}\n","        return adjusted_pricing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692583458099,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"jTFmdwdNxFRF"},"outputs":[],"source":["a=Automatic_toll_pricing(\"macet\", 2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692583461012,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"VH8OUjO7xM1q","outputId":"721aa2c8-d335-46c1-b63c-411958b1060b"},"outputs":[],"source":["a"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":512,"status":"ok","timestamp":1692576259654,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"JRqtjoqHPg12"},"outputs":[],"source":["from PIL import Image, ImageDraw,ImageFont\n","import os\n","\n","# Path ke folder gambar dan label\n","image_folder = \"/content/drive/MyDrive/LOMBA/Datathon UI/Final/test/images\"\n","label_folder = \"/content/drive/MyDrive/LOMBA/Datathon UI/Final/test/labels\"\n","class_colors = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'cyan', 'brown', 'yellow', 'magenta', 'teal', 'lime']\n","label_names = model.names\n","\n","# Mengambil daftar file gambar\n","image_files = os.listdir(image_folder)\n","\n","# Membaca label dari file teks yang sesuai dengan gambar\n","for image_file in image_files:\n","    image_name, _ = os.path.splitext(image_file)\n","    label_file = f\"{image_name}.txt\"\n","    label_path = os.path.join(label_folder, label_file)\n","    image_path = os.path.join(image_folder, image_file)\n","\n","    if os.path.exists(label_path):\n","        with open(label_path, \"r\") as f:\n","            lines = f.readlines()\n","\n","        img = Image.open(image_path)\n","        img_width, img_height = img.size\n","        draw = ImageDraw.Draw(img)\n","\n","        for line in lines:\n","            parts = line.strip().split()\n","            class_index = int(parts[0])\n","            x_center = float(parts[1]) * img_width\n","            y_center = float(parts[2]) * img_height\n","            width = float(parts[3]) * img_width\n","            height = float(parts[4]) * img_height\n","\n","            x_min = int(x_center - width / 2)\n","            y_min = int(y_center - height / 2)\n","            x_max = int(x_center + width / 2)\n","            y_max = int(y_center + height / 2)\n","\n","            # Ambil warna berdasarkan class_index\n","            class_color = class_colors[class_index]\n","\n","            # Gambar kotak pembatas dan label pada gambar\n","            draw.rectangle([x_min, y_min, x_max, y_max], outline=class_color, width=2)\n","            class_label = label_names[class_index]\n","            annotation = f\"{class_label}\"\n","            text_position = (x_min, y_min - 10)\n","            draw.text(text_position, annotation, fill=class_color)\n","\n","        # Tampilkan atau simpan gambar yang telah diberi anotasi\n","        img.save(f\"GroundTruth {image_name}.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IxVWAQH5xNcA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1133,"status":"ok","timestamp":1692576440208,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"NJ-f5fgLVBbB","outputId":"9373eeff-30e2-4640-eff4-bda6e6f8f681"},"outputs":[],"source":["# Path ke folder gambar dan label\n","image_folder = \"/content/drive/MyDrive/LOMBA/Datathon UI/Final/test/images\"\n","label_folder = \"/content/drive/MyDrive/LOMBA/Datathon UI/Final/test/labels\"\n","class_colors = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'cyan', 'brown', 'yellow', 'magenta', 'teal', 'lime']\n","label_names = model.names\n","image_files = os.listdir(image_folder)\n","\n","\n","\n","# Define a function to draw bounding boxes\n","def draw_bbox( bbox, color, label):\n","    draw = ImageDraw.Draw(img)\n","    x1, y1, x2, y2 = bbox\n","    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","\n","    x_min = x1\n","    y_min = y1-10\n","       # Define font size for the label\n","\n","\n","     # Calculate the size of the text using the default font\n","    default_font = ImageFont.load_default()\n","    text_width, text_height = draw.textsize(label, font=default_font)\n","\n","    # Define font size for the label\n","    font_size = 40  # Change the font size as desired\n","\n","    # Draw label on the image with the specified font size\n","    font = ImageFont.load_default()  # Using default font\n","    draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n","    draw.text((x_min, y_min), label, fill=color,font=font)\n","\n","for image_file in image_files :\n","  image_name,_=os.path.splitext(image_file)\n","  image_path=os.path.join(image_folder,image_file)\n","  img=Image.open(image_path)\n","  results=model(img)\n","  for r in results :\n","    boxes=r.boxes\n","    scores=r.boxes.conf.squeeze()\n","    classes=r.boxes.cls\n","    klasifikasi_kemacetan=\n","    for idx in range(len(boxes)):\n","      x, y, w, h = boxes[idx].xyxy[0]\n","      class_idx = int(classes[idx])\n","      class_label = label_names[class_idx]\n","      score = scores[idx]\n","\n","      # Draw bounding box on the composite image\n","      box_color = class_colors[class_idx]\n","      annotation = f\"{class_label}: {score:.2f}\"\n","      draw_bbox( (x, y, w, h), box_color, annotation)\n","  img.save(f\"predicted {image_file}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12804,"status":"ok","timestamp":1692583491324,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"DqM_Hjf22lSC","outputId":"71e4442c-176b-4d7a-b3e5-613903713c7f"},"outputs":[],"source":["from google.colab import files\n","from PIL import Image,ImageDraw\n","import torch\n","from torchvision import transforms\n","import torchvision.ops as ops\n","import matplotlib.pyplot as plt\n","# Upload the image you want to perform object detection on\n","\n","# Upload the image you want to perform object detection on\n","uploaded = files.upload()\n","\n","# Process the uploaded image\n","img_path = list(uploaded.keys())[0]\n","img = Image.open(img_path)\n","# Create a drawing object for the composite image\n","composite_img = Image.new('RGB', (img.width * 2, img.height))\n","draw = ImageDraw.Draw(composite_img)\n","# Perform object detection using the loaded YOLO model\n","results = model(img)\n","class_colors = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'cyan', 'brown', 'yellow', 'magenta', 'teal', 'lime']\n","\n","# Create a figure and axis to display the image\n","plt.figure(figsize=(10, 8))\n","plt.imshow(img)\n","label_names = model.names\n","\n","\n","# # Define a function to draw bounding boxes\n","# def draw_bbox( bbox, color, label):\n","#     draw = ImageDraw.Draw(img)\n","#     x, y, w, h = bbox\n","#     x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","\n","#     x1, y1 = x - w/2, y - h/2\n","#     x2, y2 = x + w/2, y + h/2\n","#     draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n","#     draw.text((x1, y1), label, fill=color)\n","\n","# # Draw predicted bounding boxes on the left side\n","# for r in results:\n","#     boxes = r.boxes\n","#     scores = r.boxes.conf.squeeze()\n","#     classes = r.boxes.cls\n","#     for idx in range(len(boxes)):\n","#         x, y, w, h = boxes[idx].xywh[0]\n","#         class_idx = int(classes[idx])\n","#         class_label = label_names[class_idx]\n","#         score = scores[idx]\n","\n","#         # Draw bounding box on the composite image\n","#         box_color = class_colors[class_idx]\n","#         annotation = f\"{class_label}: {score:.2f}\"\n","#         draw_bbox((x, y, w, h), box_color, annotation)\n","\n","# # Draw the original image on the right side\n","# composite_img.paste(img, (img.width, 0))\n","\n","# # Draw ground truth bounding boxes on the right side\n","# draw_right = ImageDraw.Draw(composite_img)\n","# for line in ground_truth_labels:\n","#     class_idx, x, y, w, h = map(float, line.split())\n","#     class_idx = int(class_idx)\n","#     class_label = label_names[class_idx]\n","#     box_color = class_colors[class_idx]\n","#     draw_bbox(draw_right, (x, y, w, h), box_color, class_label)\n","\n","# # Display the composite image\n","# plt.figure(figsize=(20, 8))\n","# plt.imshow(composite_img)\n","# plt.axis('off')\n","# plt.show()\n","\n","# Extract bounding box coordinates and scores\n","total_weight=0\n","auto_toll_pricing={}\n","\n","for r in results:\n","    boxes = r.boxes\n","    scores = r.boxes.conf.squeeze()\n","    classes = r.boxes.cls\n","    for idx in range(len(boxes)):\n","        x1, y1, x2, y2 = boxes[idx].xyxy[0]\n","        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","\n","        # Draw bounding box on the image\n","        draw = ImageDraw.Draw(img)\n","        box_color = class_colors[int(classes[idx])]\n","        draw.rectangle([x1, y1, x2, y2], outline=box_color, width=2)\n","        class_label = label_names[int(classes[idx])]\n","        total_weight+=vehicle_weights[class_label]\n","        annotation = f\"{class_label}: {scores[idx]:.2f}\"\n","\n","        # Set annotation text position and font size\n","        text_size = 12\n","        text_width, text_height = draw.textsize(annotation)\n","        text_position = (x1, y1 - text_height - 5)\n","\n","        draw.rectangle(\n","            [text_position[0], text_position[1], text_position[0] + text_width, text_position[1] + text_height],\n","            fill=box_color\n","        )\n","        draw.text(text_position, annotation, fill='white', fontsize=text_size)\n","# Assuming you have defined `img`, you can add the congestion classification text\n","congestion_level = klasifikasi_kemacetan(total_weight)\n","font = ImageFont.truetype(\"/content/Roboto-Bold.ttf\", 30)\n","base_toll_pricing=Automatic_toll_pricing(congestion_level,40000)\n","for r in results:\n","    boxes = r.boxes\n","    scores = r.boxes.conf.squeeze()\n","    classes = r.boxes.cls\n","    for idx in range(len(boxes)):\n","        # x1, y1, x2, y2 = boxes[idx].xyxy[0]\n","        # x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","\n","        # Draw bounding box on the image\n","        draw = ImageDraw.Draw(img)\n","        # box_color = class_colors[int(classes[idx])]\n","        # draw.rectangle([x1, y1, x2, y2], outline=box_color, width=2)\n","        class_label = label_names[int(classes[idx])]\n","        auto_toll_pricing[class_label]=base_toll_pricing[class_label]\n","        # # total_weight+=vehicle_weights[class_label]\n","        # annotation = f\"{class_label}: {scores[idx]:.2f}\"\n","\n","        # # Set annotation text position and font size\n","        # text_size = 12\n","        # text_width, text_height = draw.textsize(annotation)\n","        # text_position = (x1, y1 - text_height - 5)\n","\n","        # draw.rectangle(\n","        #     [text_position[0], text_position[1], text_position[0] + text_width, text_position[1] + text_height],\n","        #     fill=box_color\n","        # )\n","        # draw.text(text_position, annotation, fill='white', fontsize=text_size)\n","draw.text((10, 14), f\"Tingkat Kemacetan : {congestion_level}\", fill='white', font=font)\n","line_height = 40\n","text_x = 10\n","text_y = 60\n","# Write adjusted toll prices to the image\n","for vehicle_type, price in auto_toll_pricing.items():\n","    text = f\"{vehicle_type}: {price:.2f}\"\n","    draw.text((text_x, text_y), text, fill=\"white\", font=font)\n","    text_y += line_height\n","\n","# Display the annotated image\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692582492301,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"_7d9PgyLwnn3","outputId":"de351c62-90d0-4a86-a036-c5adada2814d"},"outputs":[],"source":[" auto_toll_pricing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"elapsed":2598,"status":"ok","timestamp":1692573101453,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"wCcJA4SpBGUs","outputId":"71f9c6c7-4fa2-49b7-f6f2-ded06f77ab3a"},"outputs":[],"source":["img"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692570703264,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"6i1q43eXstjw","outputId":"e48e42bc-f423-4277-c6b4-1b9fd8aa77a2"},"outputs":[],"source":["model.names[int(r.boxes.cls[0])]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"elapsed":3442,"status":"ok","timestamp":1692443829825,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"Gn__Gt7S3QDS","outputId":"0c1fded1-22ef-47d1-b527-9322e4a77aa0"},"outputs":[],"source":["img"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"elapsed":1331,"status":"ok","timestamp":1692115309536,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"5nmqWRS93c29","outputId":"a78f4651-4766-463c-c240-e00c8ee02b29"},"outputs":[],"source":["img"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34676,"status":"ok","timestamp":1692611432351,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"w8wXeCfA7oym","outputId":"1666e8ae-4271-41e5-8283-042d37979747"},"outputs":[],"source":["\n","pip install deepsort\n"]},{"cell_type":"markdown","metadata":{"id":"e0abII8SgPUw"},"source":["# Implementing Deep Sort"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":335,"status":"ok","timestamp":1692611962409,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"rp6yHORRgfZd"},"outputs":[],"source":["from deepsort.tracker import DeepSortTracker\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":946,"status":"ok","timestamp":1692612190833,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"BiMwVDoWhb2W"},"outputs":[],"source":["from deepsort.tracker import DeepSortTracker\n","import math\n","\n","import cv2\n","tracker = DeepSortTracker()\n","tracker.update()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import cv2\n","\n","from ultralytics import YOLO\n","model = YOLO(r'C:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\runs_1\\detect\\train2\\weights\\best.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":206592,"status":"error","timestamp":1692614188551,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"zjal7yWJgCn3","outputId":"42a4ba90-a485-48ee-f126-ed446f79e90f"},"outputs":[],"source":["# Load video\n","import numpy as np\n","from PIL import Image,ImageDraw\n","import torch\n","from torchvision import transforms\n","import torchvision.ops as ops\n","import cv2\n","video_capture = cv2.VideoCapture(r\"C:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\Material\\Kemacetan Arus Mudik di Tol Japek KM 72 (1).mp4\")  # Ganti dengan path video Anda\n","class_colors = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'cyan', 'brown', 'yellow', 'magenta', 'teal', 'lime']\n","label_names=model.names\n","# Inisialisasi variabel untuk menyimpan perpindahan kendaraan\n","vehicle_displacements = {}\n","prev_frame_data={}\n","video_capture\n","# Loop pengolahan video\n","while True:\n","    ret, frame = video_capture.read()\n","    if not ret:\n","        print(\"a\")\n","        break\n","    results = model(frame)\n","    pil_frame = Image.fromarray(frame)\n","      # Implementasikan deteksi objek (YOLO atau lainnya)\n","    for r in results:\n","        boxes = r.boxes\n","        scores = r.boxes.conf.squeeze()\n","        classes = r.boxes.cls\n","        for idx in range(len(boxes)):\n","            x1, y1, x2, y2 = boxes[idx].xyxy[0]\n","            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","\n","            # aDraw bounding box on the image\n","            draw = ImageDraw.Draw(pil_frame)\n","            box_color = class_colors[int(classes[idx])]\n","            draw.rectangle([x1, y1, x2, y2], outline=box_color, width=2)\n","            class_label = label_names[int(classes[idx])]\n","            # total_weight+=vehicle_weights[class_label]\n","            annotation = f\"{class_label}: {scores[idx]:.2f}\"\n","\n","            # Set annotation text position and font size\n","            text_size = 12\n","            text_width, text_height = draw.textsize(annotation)\n","            text_position = (x1, y1 - text_height - 5)\n","\n","            draw.rectangle(\n","                [text_position[0], text_position[1], text_position[0] + text_width, text_position[1] + text_height],\n","                fill=box_color\n","            )\n","            draw.text(text_position, annotation, fill='white', fontsize=text_size)\n","        cv2.imshow(\"frame\",np.array(pil_frame))\n","\n","\n","\n","\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","video_capture.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":737},"executionInfo":{"elapsed":1786,"status":"ok","timestamp":1692613883099,"user":{"displayName":"482 071- Krisna Bayu Dharma Putra","userId":"17263698347804146850"},"user_tz":-420},"id":"eUHK7yvCgZx8","outputId":"d4215afb-2611-40d7-e340-baed94cc368a"},"outputs":[],"source":["video_capture.read()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6npCJr5WpQQa"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\envs\\envs\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n","  FutureWarning)\n"]}],"source":["from tracker import Tracker\n","import cv2\n","\n","from ultralytics import YOLO\n","model = YOLO(r'C:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\runs_1\\detect\\train2\\weights\\best.pt')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\deep_sort\\tools\\generate_detections.py:75: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From c:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\deep_sort\\tools\\generate_detections.py:76: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From c:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\deep_sort\\tools\\generate_detections.py:77: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n","\n","WARNING:tensorflow:From c:\\Users\\krisn\\OneDrive\\Documents\\Lomba\\Datathon UI\\final\\deep_sort\\tools\\generate_detections.py:80: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"]}],"source":["tracker=Tracker()"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["0: 384x640 16 cars, 1 truck-l-, 1 truck-s-, 50.4ms\n","Speed: 1.3ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 truck-l-, 1 truck-s-, 58.1ms\n","Speed: 2.4ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 truck-l-, 1 truck-s-, 50.7ms\n","Speed: 2.0ms preprocess, 50.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 truck-l-, 1 truck-s-, 51.8ms\n","Speed: 2.5ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 18 cars, 2 truck-l-s, 1 truck-s-, 51.2ms\n","Speed: 2.2ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 1 truck-s-, 50.6ms\n","Speed: 2.4ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 truck-l-, 1 truck-s-, 57.4ms\n","Speed: 3.0ms preprocess, 57.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 17 cars, 2 truck-l-s, 1 truck-s-, 55.0ms\n","Speed: 2.4ms preprocess, 55.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 1 truck-s-, 59.2ms\n","Speed: 2.3ms preprocess, 59.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 17 cars, 2 truck-l-s, 1 truck-s-, 56.8ms\n","Speed: 3.3ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 17 cars, 2 truck-l-s, 1 truck-s-, 51.3ms\n","Speed: 2.0ms preprocess, 51.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 18 cars, 2 truck-l-s, 1 truck-s-, 51.5ms\n","Speed: 2.5ms preprocess, 51.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 1 truck-s-, 50.4ms\n","Speed: 2.0ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 1 truck-s-, 49.1ms\n","Speed: 2.5ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-s-, 52.0ms\n","Speed: 2.3ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-s-, 50.7ms\n","Speed: 1.0ms preprocess, 50.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 48.5ms\n","Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 51.0ms\n","Speed: 2.3ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 51.5ms\n","Speed: 2.0ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 53.3ms\n","Speed: 2.4ms preprocess, 53.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 54.8ms\n","Speed: 1.4ms preprocess, 54.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 57.3ms\n","Speed: 2.5ms preprocess, 57.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 52.6ms\n","Speed: 2.3ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 1 truck-s-, 53.7ms\n","Speed: 2.0ms preprocess, 53.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 60.0ms\n","Speed: 2.8ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 56.3ms\n","Speed: 2.5ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 51.9ms\n","Speed: 2.4ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 52.7ms\n","Speed: 1.0ms preprocess, 52.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.6ms\n","Speed: 3.0ms preprocess, 51.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 54.1ms\n","Speed: 2.0ms preprocess, 54.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 59.0ms\n","Speed: 2.0ms preprocess, 59.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 50.8ms\n","Speed: 2.5ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 52.3ms\n","Speed: 2.0ms preprocess, 52.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 51.9ms\n","Speed: 2.0ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 52.5ms\n","Speed: 2.0ms preprocess, 52.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 51.6ms\n","Speed: 2.0ms preprocess, 51.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 53.2ms\n","Speed: 2.4ms preprocess, 53.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 51.0ms\n","Speed: 2.5ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 52.8ms\n","Speed: 3.3ms preprocess, 52.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 52.0ms\n","Speed: 2.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 53.2ms\n","Speed: 2.0ms preprocess, 53.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 50.0ms\n","Speed: 3.1ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 51.1ms\n","Speed: 2.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 51.9ms\n","Speed: 1.2ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 50.6ms\n","Speed: 2.2ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 14 cars, 2 truck-l-s, 50.5ms\n","Speed: 2.4ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 13 cars, 2 truck-l-s, 51.9ms\n","Speed: 2.0ms preprocess, 51.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 13 cars, 2 truck-l-s, 52.5ms\n","Speed: 2.2ms preprocess, 52.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 13 cars, 2 truck-l-s, 50.8ms\n","Speed: 2.0ms preprocess, 50.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 51.5ms\n","Speed: 2.2ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 13 cars, 2 truck-l-s, 51.2ms\n","Speed: 3.0ms preprocess, 51.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 53.0ms\n","Speed: 2.0ms preprocess, 53.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 51.6ms\n","Speed: 2.0ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 50.3ms\n","Speed: 2.0ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 53.1ms\n","Speed: 2.0ms preprocess, 53.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 50.6ms\n","Speed: 2.0ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 2 truck-l-s, 51.8ms\n","Speed: 2.3ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 2 truck-l-s, 52.3ms\n","Speed: 3.0ms preprocess, 52.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 2 truck-l-s, 51.4ms\n","Speed: 2.1ms preprocess, 51.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 53.1ms\n","Speed: 2.4ms preprocess, 53.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 52.2ms\n","Speed: 1.0ms preprocess, 52.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 51.0ms\n","Speed: 2.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 51.3ms\n","Speed: 2.0ms preprocess, 51.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 51.0ms\n","Speed: 3.0ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 51.3ms\n","Speed: 1.1ms preprocess, 51.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 53.4ms\n","Speed: 2.0ms preprocess, 53.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 51.0ms\n","Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.2ms\n","Speed: 2.0ms preprocess, 51.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.5ms\n","Speed: 2.2ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 56.7ms\n","Speed: 2.1ms preprocess, 56.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 62.9ms\n","Speed: 3.0ms preprocess, 62.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 52.6ms\n","Speed: 2.1ms preprocess, 52.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 50.9ms\n","Speed: 2.3ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 52.3ms\n","Speed: 1.0ms preprocess, 52.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 55.3ms\n","Speed: 1.3ms preprocess, 55.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 55.4ms\n","Speed: 1.4ms preprocess, 55.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 1 truck-m-, 51.7ms\n","Speed: 2.0ms preprocess, 51.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 1 truck-m-, 49.6ms\n","Speed: 3.0ms preprocess, 49.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 cars, 2 truck-l-s, 1 truck-m-, 54.7ms\n","Speed: 2.0ms preprocess, 54.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 1 truck-m-, 52.3ms\n","Speed: 2.4ms preprocess, 52.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 1 truck-m-, 50.9ms\n","Speed: 2.0ms preprocess, 50.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-m-, 55.7ms\n","Speed: 1.0ms preprocess, 55.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 18 cars, 2 truck-l-s, 1 truck-m-, 50.9ms\n","Speed: 2.0ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 18 cars, 2 truck-l-s, 1 truck-m-, 49.8ms\n","Speed: 2.3ms preprocess, 49.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 17 cars, 2 truck-l-s, 1 truck-m-, 50.6ms\n","Speed: 2.0ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 17 cars, 2 truck-l-s, 1 truck-m-, 51.1ms\n","Speed: 1.3ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 18 cars, 2 truck-l-s, 1 truck-m-, 64.3ms\n","Speed: 2.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 1 truck-m-, 52.3ms\n","Speed: 2.0ms preprocess, 52.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 18 cars, 2 truck-l-s, 1 truck-m-, 51.0ms\n","Speed: 2.6ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-m-, 51.0ms\n","Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-m-, 50.0ms\n","Speed: 1.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 53.0ms\n","Speed: 1.0ms preprocess, 53.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 50.8ms\n","Speed: 2.3ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 50.6ms\n","Speed: 2.2ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 51.3ms\n","Speed: 1.2ms preprocess, 51.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 51.1ms\n","Speed: 2.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 21 cars, 2 truck-l-s, 50.6ms\n","Speed: 1.5ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 50.3ms\n","Speed: 2.0ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 52.0ms\n","Speed: 2.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 57.5ms\n","Speed: 2.0ms preprocess, 57.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 50.8ms\n","Speed: 2.0ms preprocess, 50.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 21 cars, 2 truck-l-s, 52.0ms\n","Speed: 1.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 50.7ms\n","Speed: 2.0ms preprocess, 50.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 48.9ms\n","Speed: 1.0ms preprocess, 48.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 51.3ms\n","Speed: 2.0ms preprocess, 51.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 50.4ms\n","Speed: 2.0ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 22 cars, 2 truck-l-s, 51.9ms\n","Speed: 1.0ms preprocess, 51.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 51.6ms\n","Speed: 1.0ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 22 cars, 2 truck-l-s, 51.3ms\n","Speed: 1.2ms preprocess, 51.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 52.2ms\n","Speed: 1.3ms preprocess, 52.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 20 cars, 2 truck-l-s, 51.3ms\n","Speed: 2.0ms preprocess, 51.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 50.9ms\n","Speed: 1.0ms preprocess, 50.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 21 cars, 2 truck-l-s, 50.9ms\n","Speed: 2.0ms preprocess, 50.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 21 cars, 2 truck-l-s, 51.8ms\n","Speed: 1.2ms preprocess, 51.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 23 cars, 2 truck-l-s, 52.0ms\n","Speed: 2.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 24 cars, 2 truck-l-s, 51.2ms\n","Speed: 1.5ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 21 cars, 2 truck-l-s, 50.4ms\n","Speed: 1.2ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 22 cars, 2 truck-l-s, 52.7ms\n","Speed: 2.0ms preprocess, 52.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 22 cars, 2 truck-l-s, 53.8ms\n","Speed: 2.0ms preprocess, 53.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 54.9ms\n","Speed: 2.0ms preprocess, 54.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 bus-l-, 19 cars, 2 truck-l-s, 53.0ms\n","Speed: 1.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 51.7ms\n","Speed: 2.0ms preprocess, 51.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 52.9ms\n","Speed: 1.0ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 50.8ms\n","Speed: 2.0ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 51.6ms\n","Speed: 2.4ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 50.9ms\n","Speed: 2.0ms preprocess, 50.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 52.7ms\n","Speed: 2.0ms preprocess, 52.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 52.1ms\n","Speed: 2.5ms preprocess, 52.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 52.7ms\n","Speed: 1.0ms preprocess, 52.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 1 truck-m-, 50.9ms\n","Speed: 2.0ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 1 truck-m-, 50.8ms\n","Speed: 2.1ms preprocess, 50.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.1ms\n","Speed: 1.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.2ms\n","Speed: 1.5ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 1 truck-m-, 51.3ms\n","Speed: 2.0ms preprocess, 51.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.0ms\n","Speed: 2.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.4ms\n","Speed: 2.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 50.4ms\n","Speed: 2.0ms preprocess, 50.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 58.0ms\n","Speed: 2.0ms preprocess, 58.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 59.6ms\n","Speed: 2.4ms preprocess, 59.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 52.4ms\n","Speed: 3.5ms preprocess, 52.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 50.1ms\n","Speed: 2.2ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.1ms\n","Speed: 3.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 3 truck-l-s, 52.0ms\n","Speed: 2.0ms preprocess, 52.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.4ms\n","Speed: 2.0ms preprocess, 51.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 52.2ms\n","Speed: 2.0ms preprocess, 52.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.3ms\n","Speed: 2.0ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.5ms\n","Speed: 3.0ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.3ms\n","Speed: 2.2ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.7ms\n","Speed: 2.0ms preprocess, 50.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 51.1ms\n","Speed: 2.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 54.8ms\n","Speed: 1.2ms preprocess, 54.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 56.3ms\n","Speed: 2.0ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 1 truck-m-, 52.2ms\n","Speed: 2.0ms preprocess, 52.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.6ms\n","Speed: 1.2ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.7ms\n","Speed: 2.0ms preprocess, 51.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 51.2ms\n","Speed: 3.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 51.2ms\n","Speed: 1.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 54.4ms\n","Speed: 2.0ms preprocess, 54.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 51.5ms\n","Speed: 2.0ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 57.4ms\n","Speed: 2.0ms preprocess, 57.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 51.4ms\n","Speed: 1.0ms preprocess, 51.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 2 truck-l-s, 1 truck-m-, 53.6ms\n","Speed: 1.0ms preprocess, 53.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 58.7ms\n","Speed: 2.1ms preprocess, 58.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 52.8ms\n","Speed: 1.0ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 50.2ms\n","Speed: 1.5ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 50.2ms\n","Speed: 2.0ms preprocess, 50.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 49.6ms\n","Speed: 2.0ms preprocess, 49.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 50.5ms\n","Speed: 1.2ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 52.8ms\n","Speed: 2.0ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 51.0ms\n","Speed: 2.3ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 53.5ms\n","Speed: 2.0ms preprocess, 53.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 51.2ms\n","Speed: 2.0ms preprocess, 51.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 49.5ms\n","Speed: 1.5ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 51.1ms\n","Speed: 2.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 50.7ms\n","Speed: 2.5ms preprocess, 50.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 49.6ms\n","Speed: 2.0ms preprocess, 49.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 51.6ms\n","Speed: 2.0ms preprocess, 51.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 51.3ms\n","Speed: 3.1ms preprocess, 51.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 51.6ms\n","Speed: 2.0ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 50.9ms\n","Speed: 1.0ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 55.0ms\n","Speed: 1.2ms preprocess, 55.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 53.4ms\n","Speed: 3.0ms preprocess, 53.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 51.0ms\n","Speed: 1.5ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 48.7ms\n","Speed: 2.0ms preprocess, 48.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 50.1ms\n","Speed: 2.0ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 50.4ms\n","Speed: 2.2ms preprocess, 50.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 2 truck-l-s, 51.2ms\n","Speed: 1.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 51.4ms\n","Speed: 2.1ms preprocess, 51.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 50.5ms\n","Speed: 2.4ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 2 truck-l-s, 60.6ms\n","Speed: 2.0ms preprocess, 60.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 50.2ms\n","Speed: 3.0ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 50.5ms\n","Speed: 2.3ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 50.1ms\n","Speed: 1.0ms preprocess, 50.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 52.4ms\n","Speed: 2.0ms preprocess, 52.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 50.6ms\n","Speed: 2.3ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 50.4ms\n","Speed: 2.0ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 51.8ms\n","Speed: 1.0ms preprocess, 51.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 2 truck-l-s, 51.7ms\n","Speed: 2.0ms preprocess, 51.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 cars, 2 truck-l-s, 52.8ms\n","Speed: 1.0ms preprocess, 52.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 cars, 2 truck-l-s, 50.2ms\n","Speed: 1.0ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 52.1ms\n","Speed: 1.0ms preprocess, 52.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 50.8ms\n","Speed: 1.3ms preprocess, 50.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 2 truck-l-s, 50.1ms\n","Speed: 2.1ms preprocess, 50.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-m-, 50.5ms\n","Speed: 2.0ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 2 truck-l-s, 1 truck-m-, 50.8ms\n","Speed: 2.0ms preprocess, 50.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 2 truck-l-s, 1 truck-m-, 50.4ms\n","Speed: 2.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 2 truck-l-s, 1 truck-m-, 50.7ms\n","Speed: 2.0ms preprocess, 50.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 2 truck-l-s, 1 truck-m-, 51.6ms\n","Speed: 2.0ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 1 small truck, 2 truck-l-s, 1 truck-m-, 50.4ms\n","Speed: 1.3ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 57.8ms\n","Speed: 1.7ms preprocess, 57.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 51.2ms\n","Speed: 2.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 49.3ms\n","Speed: 2.0ms preprocess, 49.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.2ms\n","Speed: 2.2ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 49.9ms\n","Speed: 1.2ms preprocess, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 52.2ms\n","Speed: 2.0ms preprocess, 52.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.6ms\n","Speed: 2.0ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 51.3ms\n","Speed: 2.0ms preprocess, 51.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 truck-l-, 1 truck-m-, 51.2ms\n","Speed: 2.0ms preprocess, 51.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.7ms\n","Speed: 2.0ms preprocess, 50.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 51.6ms\n","Speed: 1.4ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 48.6ms\n","Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.1ms\n","Speed: 2.2ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.6ms\n","Speed: 2.0ms preprocess, 50.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 49.9ms\n","Speed: 2.5ms preprocess, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.3ms\n","Speed: 2.0ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 49.9ms\n","Speed: 3.0ms preprocess, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.7ms\n","Speed: 3.0ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.5ms\n","Speed: 2.0ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.8ms\n","Speed: 2.0ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.8ms\n","Speed: 2.1ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.9ms\n","Speed: 1.2ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 49.8ms\n","Speed: 2.4ms preprocess, 49.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 57.0ms\n","Speed: 2.5ms preprocess, 57.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 53.2ms\n","Speed: 1.0ms preprocess, 53.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 50.8ms\n","Speed: 2.0ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 57.9ms\n","Speed: 2.0ms preprocess, 57.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 1 small truck, 1 truck-l-, 1 truck-m-, 54.0ms\n","Speed: 1.0ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 1 truck-l-, 1 truck-m-, 52.1ms\n","Speed: 1.0ms preprocess, 52.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 1 truck-l-, 1 truck-m-, 52.4ms\n","Speed: 1.0ms preprocess, 52.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 2 truck-l-s, 1 truck-m-, 51.0ms\n","Speed: 1.1ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 1 truck-l-, 1 truck-m-, 1 truck-s-, 57.0ms\n","Speed: 2.0ms preprocess, 57.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 1 truck-l-, 1 truck-m-, 1 truck-s-, 58.2ms\n","Speed: 2.2ms preprocess, 58.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 1 truck-l-, 1 truck-m-, 1 truck-s-, 59.1ms\n","Speed: 3.1ms preprocess, 59.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 1 truck-l-, 1 truck-m-, 1 truck-s-, 53.4ms\n","Speed: 2.1ms preprocess, 53.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 1 truck-l-, 1 truck-m-, 1 truck-s-, 49.8ms\n","Speed: 2.5ms preprocess, 49.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 3 truck-l-s, 1 truck-m-, 1 truck-s-, 53.8ms\n","Speed: 2.1ms preprocess, 53.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 3 truck-l-s, 1 truck-m-, 1 truck-s-, 55.1ms\n","Speed: 2.1ms preprocess, 55.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 cars, 2 truck-l-s, 1 truck-m-, 1 truck-s-, 55.6ms\n","Speed: 2.0ms preprocess, 55.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 cars, 1 truck-l-, 1 truck-m-, 1 truck-s-, 54.6ms\n","Speed: 2.3ms preprocess, 54.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 16 cars, 2 truck-l-s, 1 truck-m-, 1 truck-s-, 56.3ms\n","Speed: 2.0ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"name":"stdout","output_type":"stream","text":["a\n"]}],"source":["# Load video\n","import numpy as np\n","from PIL import Image,ImageDraw\n","import torch\n","from torchvision import transforms\n","import torchvision.ops as ops\n","import cv2\n","import random\n","colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for j in range(10)]\n","\n","video_capture = cv2.VideoCapture(r\"Material\\Kemacetan Arus Mudik di Tol Japek KM 72 (1).mp4\")  # Ganti dengan path video Anda\n","class_colors = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'cyan', 'brown', 'yellow', 'magenta', 'teal', 'lime']\n","label_names=model.names\n","# Inisialisasi variabel untuk menyimpan perpindahan kendaraan\n","vehicle_displacements = {}\n","prev_frame_data={}\n","detection_threshold = 0.20\n","classes=model.names\n","frame_width = int(video_capture.get(3))\n","frame_height = int(video_capture.get(4))\n","fps = int(video_capture.get(5))\n","output_filename = \"output_video\"  # Change to your desired output video filename\n","\n","# Create a VideoWriter object to save the output video\n","fourcc = cv2.VideoWriter_fourcc(*'H264')\n","out = cv2.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n","total_weight=0\n"," \n","auto_toll_pricing={}\n","# Loop pengolahan video\n","while True:\n","    ret, frame = video_capture.read()\n","    if not ret:\n","        print(\"a\")\n","        break\n","    results = model(frame)\n","    pil_frame = Image.fromarray(frame)\n","      # Implementasikan deteksi objek (YOLO atau lainnya)\n","    # for result in results:\n","    #     detections = []\n","    #     for r in result.boxes.data.tolist():\n","    #         x1, y1, x2, y2, score, class_id = r\n","    #         x1 = int(x1)\n","    #         x2 = int(x2)\n","    #         y1 = int(y1)\n","    #         y2 = int(y2)\n","    #         class_id = int(class_id)\n","    #         if score > detection_threshold:\n","    #             detections.append([x1, y1, x2, y2, score])\n","    #         label = classes[class_id]\n","    #         label_color = colors[class_id % len(colors)]\n","    #         cv2.rectangle(frame, (x1, y1), (x2, y2), label_color, 3)\n","            \n","    # Implementasikan deteksi objek (YOLO atau lainnya)\n","    for result in results:\n","        detections = []\n","        for r in result.boxes.data.tolist():\n","            x1, y1, x2, y2, score, class_id = r\n","            x1 = int(x1)\n","            x2 = int(x2)\n","            y1 = int(y1)\n","            y2 = int(y2)\n","            class_id = int(class_id)\n","            if score > detection_threshold:\n","                detections.append([x1, y1, x2, y2, score])\n","            label = classes[class_id]\n","            \n","            label_color = colors[class_id % len(colors)]\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), label_color, 3)\n","            total_weight+=vehicle_weights[label_names[class_id]]\n","            \n","            # Set text position above the bounding box\n","            text_x = x1+50\n","            text_y = y1 -10\n","\n","            # Choose a contrasting color for the text\n","            text_color = (255 - label_color[0], 255 - label_color[1], 255 - label_color[2])\n","\n","            # Format the label with score and class name\n","            text = f\"{label} - Score: {score:.2f}\"\n","\n","            # Put text on the frame\n","            cv2.putText(\n","                frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA\n","            )\n","              # Format the label with class name, score, and track ID\n","\n","            # # Put text on the frame\n","            # cv2.putText(\n","            #     frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA\n","            # )\n","        tracker.update(frame, detections)\n","        for track in tracker.tracks:\n","            bbox = track.bbox\n","            x1, y1, x2, y2 = bbox\n","            track_id = track.track_id\n","            color = colors[track_id % len(colors)]\n","             # Use the score from the tracker if available\n","\n","            # Set text position slightly above the top-left corner of the bounding box\n","            text_position = (int(x1), int(y1) - 10)\n","\n","            # Choose a contrasting color for text depending on the bounding box color\n","            text_color = (255 - color[0], 255 - color[1], 255 - color[2])\n","\n","            # Format the label with score and track ID\n","            text = f\"{track_id}\" if score is not None else None\n","            # Put text on the frame\n","            cv2.putText(\n","                frame, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA\n","    )\n","            # cv2.putText(frame, str(track_id), (int(x1), int(y1)), 0, 5e-3 * 200, (0, 255, 0), 2) \n","            \n","\n","            # # aDraw bounding box on the image\n","            # draw = ImageDraw.Draw(pil_frame)\n","            # box_color = class_colors[int(classes[idx])]\n","            # draw.rectangle([x1, y1, x2, y2], outline=box_color, width=2)\n","            # class_label = label_names[int(classes[idx])]\n","           \n","            # annotation = f\"{class_label}: {scores[idx]:.2f}\"\n","\n","            # # Set annotation text position and font size\n","            # text_size = 12\n","            # text_width, text_height = draw.textsize(annotation)\n","            # text_position = (x1, y1 - text_height - 5)\n","\n","            # draw.rectangle(\n","            #     [text_position[0], text_position[1], text_position[0] + text_width, text_position[1] + text_height],\n","            #     fill=box_color\n","            # )\n","            # draw.text(text_position, annotation, fill='white', fontsize=text_size)\n","        congestion_level=klasifikasi_kemacetan(total_weight)\n","        base_toll_pricing=Automatic_toll_pricing(congestion_level,40000) \n","        auto_toll_pricing[label_names[class_id]]=base_toll_pricing[label_names[class_id]]\n","        cv2.putText(frame, f\"Tingkat Kemacetan : {congestion_level}\", (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA) \n","        height=155\n","        for i in auto_toll_pricing.items():\n","          cv2.putText(frame, f\"{i[0]} : {i[1]}\", (10, height), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)  \n","          height+=15\n","        cv2.imshow(\"frame\",np.array(frame))\n","    out.write(frame)\n","\n","\n","\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","video_capture.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/plain":["{0: 'big bus',\n"," 1: 'big truck',\n"," 2: 'bus-l-',\n"," 3: 'bus-s-',\n"," 4: 'car',\n"," 5: 'mid truck',\n"," 6: 'small bus',\n"," 7: 'small truck',\n"," 8: 'truck-l-',\n"," 9: 'truck-m-',\n"," 10: 'truck-s-',\n"," 11: 'truck-xl-'}"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["model.names"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN/D86upsjSD0pG2tqD/b/f","mount_file_id":"1_r2FJs4uLdlvaOGP7GfmOA8T8eMMBZIB","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":0}
